{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b53dc418",
   "metadata": {},
   "source": [
    "# DS 2002 Midterm Project Spring 2023 - Cheryl Bai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ad4b51",
   "metadata": {},
   "source": [
    "This project was done using the Sakila sample dataset from Microsoft."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f372e2",
   "metadata": {},
   "source": [
    "#### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f9b395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "import pymongo\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea27679",
   "metadata": {},
   "source": [
    "#### Declare & Assign Connection Variables for the MongoDB Server, the MySQL Server & Databases with which You'll be Working "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1158dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE!!!\n",
    "mysql_uid = \"root\"\n",
    "mysql_pwd = \"Passw0rd123\"\n",
    "\n",
    "atlas_cluster_name = \"DS2002\"\n",
    "atlas_user_name = \"eqk9vb\"\n",
    "atlas_password = \"RtDwy7sYyhTm1pFB\"\n",
    "\n",
    "conn_str = {\"local\" : f\"mongodb://localhost:27017/\",\n",
    "    \"atlas\" : f\"mongodb+srv://{atlas_user_name}:{atlas_password}@{atlas_cluster_name}.mongodb.net\"\n",
    "}\n",
    "\n",
    "src_dbname = \"sakila\"\n",
    "dst_dbname = \"sakila_dw\"\n",
    "\n",
    "print(f\"Local Connection String: {conn_str['local']}\")\n",
    "print(f\"Atlas Connection String: {conn_str['atlas']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3cf12b",
   "metadata": {},
   "source": [
    "#### Define Functions for Getting Data From and Setting Data Into Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d023ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql_dataframe(user_id, pwd, db_name, sql_query):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    conn_str = f\"mysql+pymysql://{user_id}:{pwd}@localhost/{db_name}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    \n",
    "    '''Invoke the pd.read_sql() function to query the database, and fill a Pandas DataFrame.'''\n",
    "    conn = sqlEngine.connect()\n",
    "    dframe = pd.read_sql(sql_query, conn);\n",
    "    conn.close()\n",
    "    \n",
    "    return dframe\n",
    "\n",
    "\n",
    "def get_mongo_dataframe(connect_str, db_name, collection, query):\n",
    "    '''Create a connection to MongoDB'''\n",
    "    client = pymongo.MongoClient(connect_str)\n",
    "    \n",
    "    '''Query MongoDB, and fill a python list with documents to create a DataFrame'''\n",
    "    db = client[db_name]\n",
    "    dframe = pd.DataFrame(list(db[collection].find(query)))\n",
    "    dframe.drop(['_id'], axis=1, inplace=True)\n",
    "    client.close()\n",
    "    return dframe\n",
    "\n",
    "\n",
    "def set_dataframe(user_id, pwd, db_name, df, table_name, pk_column, db_operation):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    conn_str = f\"mysql+pymysql://{user_id}:{pwd}@localhost/{db_name}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    connection = sqlEngine.connect()\n",
    "    \n",
    "    '''Invoke the Pandas DataFrame .to_sql( ) function to either create, or append to, a table'''\n",
    "    if db_operation == \"insert\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='replace')\n",
    "        sqlEngine.execute(f\"ALTER TABLE {table_name} ADD PRIMARY KEY ({pk_column});\")\n",
    "            \n",
    "    elif db_operation == \"update\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='append')\n",
    "    \n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83c57be",
   "metadata": {},
   "source": [
    "#### Create the New Data Warehouse Database and Switch the Connection Context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0228f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_str = f\"mysql+pymysql://{user_id}:{pwd}@{host_name}\"\n",
    "sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "\n",
    "sqlEngine.execute(f\"DROP DATABASE IF EXISTS `{dst_dbname}`;\")\n",
    "sqlEngine.execute(f\"CREATE DATABASE `{dst_dbname}`;\")\n",
    "sqlEngine.execute(f\"USE {dst_dbname};\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6322e123",
   "metadata": {},
   "source": [
    "#### Populate MongoDB with Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7a62c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(conn_str[\"atlas\"])\n",
    "db = client[src_dbname]\n",
    "\n",
    "# Gets the path of the Current Working Directory for this Notebook, and then Appends the 'data' directory.\n",
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "json_files = {\"staff\" : 'sakila_staff.json',\n",
    "              \"store\" : 'sakila_stores.json',\n",
    "             }\n",
    "\n",
    "for file in json_files:\n",
    "    db.drop_collection(file)\n",
    "    json_file = os.path.join(data_dir, json_files[file])\n",
    "    with open(json_file, 'r') as openfile:\n",
    "        json_object = json.load(openfile)\n",
    "        file = db[file]\n",
    "        result = file.insert_many(json_object)\n",
    "        print(f\"{file} was successfully loaded.\")\n",
    "\n",
    "        \n",
    "client.close()        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83838566",
   "metadata": {},
   "source": [
    "### 1.0 Create and Populate the Dimension Tables\n",
    "#### 1.1 Extract Data from the Source MySQL Database Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81767c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_film = \"SELECT * FROM sakila.film;\"\n",
    "df_film = get_dataframe(user_id, pwd, host_name, src_dbname, sql_film)\n",
    "df_film.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3774c7",
   "metadata": {},
   "source": [
    "#### 1.2 Extract Data from the Source MongoDB Collections into Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b2805",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {}\n",
    "collection = \"staff\"\n",
    "\n",
    "df_staff = get_mongo_dataframe(conn_str['atlas'], src_dbname, collection, query)\n",
    "df_staff.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c812a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {}\n",
    "collection = \"store\"\n",
    "\n",
    "df_store = get_mongo_dataframe(conn_str['atlas'], src_dbname, collection, query)\n",
    "df_store.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6837281e",
   "metadata": {},
   "source": [
    "#### 1.3 Extract Data from the Local Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ddc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer = pd.read_csv(\"sakila_customer.csv\")\n",
    "df_customer.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb54f7fc",
   "metadata": {},
   "source": [
    "#### 1.4 Perform Any Necessary Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a17add",
   "metadata": {},
   "source": [
    "#### 1.5 Load the Transformed Dataframes into the New Data Warehouse by Creating New Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e58686e",
   "metadata": {},
   "source": [
    "#### 1.6 Validate that the New Dimension Tables were Created"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ffcf07",
   "metadata": {},
   "source": [
    "### 2.0 Create and Populate the Fact Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529291f9",
   "metadata": {},
   "source": [
    "### 3.0 Validate that the New Fact Table was Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6034d604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
